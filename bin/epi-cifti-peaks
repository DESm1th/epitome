#!/usr/bin/env python
"""
Takes a cifti map ('dscalar.nii' and outputs a csv of peak vertices)

Usage:
    epi-cifti-peaks [options] <func.dscalar.nii> <Lsurf> <Rsurf>

Arguments:
    <func.dscalar.nii>    Input map.
    <L.surf.gii>          Corresponding Left surface
    <R.surf.gii>          Corresponding Right surface file

Options:
    --surface-distance   minimum distance in mm [default: 40] between extrema of the same type.
    --volume-distance    minimum distance in mm [default: 40] between extrema of the same type.
    --min-threshold      the largest value [default: -2.85] to consider for being a minimum
    --max-threshold      the smallest value [default: 2.85] to consider for being a maximum
    --outputcsv FILE     Filename of the output csv table
    --debug              Debug logging
    -n,--dry-run         Dry run
    -h, --help           Prints this message

DETAILS

Default name for the output csv taken from the input file.
i.e. func.dscalar.nii --> func_peaks.csv

Written by Erin W Dickie, June 3, 2016
"""

import os
import sys
import subprocess
import numpy as np
import scipy as sp
import nibabel as nib
import pandas as pd
import tempfile
import shutil
import nibabel.gifti.giftiio
import epitome as epi
from epitome.docopt import docopt

def docmd(cmdlist):
    "sends a command (inputed as a list) to the shell"
    if DEBUG: print ' '.join(cmdlist)
    if not DRYRUN: subprocess.call(cmdlist)

def load_surfaceonly(filename, tempdir = tmpdir):
    '''
    separate a cifti file into surfaces,
    then loads and concatenates the surface data
    '''
    ## separate the cifti file into left and right surfaces
    L_data_surf=os.path.join(tempdir, 'Ldata.func.gii')
    R_data_surf=os.path.join(tempdir, 'Rdata.func.gii')
    docmd(['wb_command','-cifti-separate', filename, 'COLUMN',
        '-metric', 'CORTEX_LEFT', L_data_surf,
        '-metric', 'CORTEX_RIGHT', R_data_surf])

    ## load both surfaces and concatenate them together
    Ldata = epi.utilities.load_gii_data(L_data_surf)
    Rdata = epi.utilities.load_gii_data(R_data_surf)

    return Ldata, Rdata

def main():
    global DEBUG
    global DRYRUN

    arguments = docopt(__doc__)
    data_file = arguments['<func.dscalar.nii>']
    surfL = arguments['<L.surf.gii>']
    surfR = arguments['<R.surf.gii>']
    surf_distance = arguments['--surface-distance']
    volume_distance = arguments['--volume-distance']
    min_threshold = arguments['--min-threshold']
    max_threshold = arguments['--max-threshold']
    outputcsv = arguments['--outputcsv']
    DEBUG = arguments['--debug']
    DRYRUN = arguments['--dry-run']

    ## make the tempdir
    tempdir = tempfile.mkdtemp()

    ## run wb_command -cifti-extrema to find the peak locations
    extrema_file = os.path.join(tmpdir,'extrema.dscalar.nii')
    docmd(['wb_command',
           '-cifti-extrema',
           data_file,
           str(surf_distance), str(volume_distance),'COLUMN',
           extrema_file,
           '-left-surface', surfL, '-right-surface', surfR,
           '-threshold', str(min_threshold), str(max_threshold)])

    ## read in the extrema file from above
    Lextrema, Rextrema = load_surfaceonly(extrema_file, tempdir = tmpdir)
    Lverts = np.nonzero(Lextrema)[0]  # indices - vertex id for peak in left
    Rverts = np.nonzero(Rextrema)[0]  # indices - vertex id for peak in right

    ## read in the original data for the value column
    Ldata, Rdata = load_surfaceonly(data_file, tempdir = tmpdir)

    ## read in the surface mni coordinates
    surf_dist_nib = nibabel.gifti.giftiio.read(surfL)
    Lcoords = surf_dist_nib.getArraysFromIntent('NIFTI_INTENT_POINTSET')[0].data
    surf_dist_nib = nibabel.gifti.giftiio.read(surfR)
    Rcoords = surf_dist_nib.getArraysFromIntent('NIFTI_INTENT_POINTSET')[0].data

    ## put all this info together into one pandas dataframe
    dfL = pd.DataFrame({"hemisphere": 'L',
                    "vertex": Lverts,
                    'x': np.round(Lcoords[Lverts,0]),
                    'y': np.round(Lcoords[Lverts,1]),
                    'z': np.round(Lcoords[Lverts,2]),
                    'value': np.reshape(Ldata[Lverts],(len(Lverts),))})
    dfR = pd.DataFrame({"hemisphere": 'R',
                        "vertex": Rverts,
                        'x': np.round(Rcoords[Rverts,0]),
                        'y': np.round(Rcoords[Rverts,1]),
                        'z': np.round(Rcoords[Rverts,2]),
                        'value': np.reshape(Rdata[Rverts],(len(Rverts),))})
    df = dfL.append(dfR, ignore_index = True)

    ## if not outputname is given, create it from the input dscalar map
    if not outputcsv:
        outputcsv = os.path.basename(data_file).replace('.dtseries.nii','_peaks.csv')

    ## write the table out to the outputcsv
    df.to_csv(outputcsv,
          columns = ['hemisphere','vertex','x','y','z', 'value'],
          index=False)
    ## remove the tempdirectory
    shutil.rmtree(tempdir)

if __name__ == '__main__':
    main()
